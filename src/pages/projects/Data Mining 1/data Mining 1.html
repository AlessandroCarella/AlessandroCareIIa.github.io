<p>
    This is one of the first projects i have worked on during my Master in Data
    Science and Business Informatics. The project analyzes a Spotify Tracks
    dataset which was provided by the teachers, containing approximately 15,000
    songs with 24 attributes including duration, popularity, danceability,
    energy, and genre. Me and my colleagues, other than friends, applied the
    following data mining techniques that were tought us during the classes:
    data preparation, clustering, classification, regression, and pattern
    mining.
</p>
<p>
    You can find the link to the project github repository, report in the side
    panel of this page. The linked class notes refer to the data mining 2 class
    since the second module expanded the first class concepts.
</p>

<h2 id="what-i-learned">What I Learned</h2>
<p>
    This project proved to be an invaluable learning experience that shaped my
    understanding of practical data mining applications.
</p>
<p>
    Working collaboratively with my colleagues (who became friends in the
    meanwhile) taught me that data science is as much about teamwork and
    communication as it is about technical skills. Dividing responsibilities,
    reviewing each other's progresses, and discussing approaches helped me
    develop better coding practices and learn to articulate technical concepts
    clearly.
</p>
<p>
    <strong
        >The biggest technical lesson was understanding that real-world data is
        messy.</strong
    >
    The data preparation phase consumed far more time than I initially expected,
    but it taught me critical thinking about data quality. Deciding when to
    impute missing values versus removing them, determining the correct outlier
    thresholds, and justifying each preprocessing decision required careful
    consideration of the impact on our models. I learned that these early
    decisions fundamentally change project outcomes since no sophisticated
    algorithm can compensate for poor data preparation.
</p>
<p>
    The clustering analysis was humbling. Despite implementing seven different
    algorithms with various parameter configurations, we achived modest
    performance metrics. This taught me that
    <strong>not every dataset is naturally "clusterable"</strong> and that
    sometimes the data, especially if multifaced as music ones, simply doesn't
    have clear groupings. Learning to interpret and communicate these
    limitations honestly is as important as celebrating successes.
</p>
<p>
    The regression work reinforced the importance of understanding real-world
    data's relationships. Discovering that n_beats could predict duration with
    94.7% accuracy seems obvious in retrospect, longer songs naturally have more
    beats, but identifying such strong predictors requires domain knowledge
    combined with statistical analysis.
</p>
<p>
    <strong
        >Perhaps most importantly, this project taught me the iterative nature
        of data science.</strong
    >
    We constantly cycled between analysis, interpretation, refinement, and
    re-analysis. Initial approaches rarely worked perfectly; success came from
    experimentation, learning from failures, and incremental improvement.
</p>
<p>
    Looking back through the commit history, I can see my growth not just in
    technical proficiency with Python libraries (scikit-learn, pandas,
    matplotlib) but in my analytical thinking and problem-solving approach. This
    foundational project established methodologies and best practices that I
    continue to apply in my work today.
</p>

<p>
    Here is a quick summary of what we worked on as a group, but you can see my
    specific contributions through the
    <a
        href="https://github.com/AlessandroCarella/data-mining-project/commits/main/"
        >github commits page</a
    >.
</p>

<h2 id="data-understanding-and-preparation">
    Data Understanding and Preparation
</h2>
<p>
    The initial phase involved data quality assessment and preprocessing. We
    identified significant missing values in three attributes (Processing, Mode,
    and Popularity_confidence) and addressed them through imputation and
    deletion strategies. Using the Interquartile Range (IQR) method with a 1.5
    scale, outliers were removed, with observations containing two or more
    outlier attributes eliminated. This reduced the dataset to 14,237 rows and
    preserved data integrity. Additionally, highly correlated variables were
    removed, including features_duration_ms (which had a 1:1 correlation with
    duration_ms) and n_bars (which had a 0.98 correlation with n_beats).
    <img src="heatmap.png" alt="correlation matrix" />
</p>
<h2 id="clustering-analysis">Clustering Analysis</h2>
<p>
    Multiple clustering algorithms were evaluated, including kMeans, Bisecting
    kMeans, kModes, Hierarchical clustering variants, DBSCAN, OPTICS, and
    HDBSCAN. Most algorithms struggled with the dataset, with many producing
    optimal results only when forcing two clusters. The best performing approach
    was Hierarchical clustering using Group Average Linkage with a threshold of
    10 and maxclust criterion, achieving a very low Silhouette score of 0.11.
    This method was selected since it was the best at balancing between
    performance and <em>"robustness"</em> against outliers and noise.
</p>
<h2 id="classification-models">Classification Models</h2>
<p>
    Classification focused on predicting music genres using both the original 20
    genre classes and a reduced set of 4 grouped genres (created through kMeans
    clustering). Three primary models were tested: K-Nearest Neighbors, Naive
    Bayes, and Decision Trees. KNN was the best performing classifier,
    particularly when using grouped genres, achieving good test set metrics of
    74% accuracy, 74% precision, 67% recall, and 73% F1-score.
    <img src="learningCurve.png" alt="results" />
</p>
<h2 id="regression-analysis">Regression Analysis</h2>
<p>
    The regression component targeted three continuous variables: duration,
    popularity, and danceability. Various models were implemented, including
    simple and multiple linear regression (with Standard, Ridge, and Lasso
    regularization), KNN-based regression, and decision tree regression. The
    best results emerged for duration prediction using n_beats as a predictor,
    achieving an RÂ² score of 0.947. Multiple regression with Ridge
    regularization consistently performed well across targets, while Lasso
    regularization underperformed due to the dataset's relatively low
    complexity.
</p>
<h2 id="pattern-mining">Pattern Mining</h2>
<p>
    Using Apriori and FP-Growth algorithms, we extracted frequent itemsets,
    closed itemsets, and maximal itemsets from preprocessed data with binned
    continuous variables. Optimal parameters were identified at 25% support and
    65% confidence, yielding 208 association rules. The analysis successfully
    predicted the "explicit" variable, demonstrating that very long songs with
    very low liveliness and speechiness tend to be non-explicit.
</p>
